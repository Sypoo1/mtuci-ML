{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG8GuNGW94Ho",
        "outputId": "7a25db6c-15cc-4cab-81b5-b41213e05cc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/sypoo/mtuci/ml/.venv/bin/python: No module named pip\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pymorphy3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UyPLvbl-UBPq"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import pymorphy3\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from nltk.stem.snowball import RussianStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I6SVCFYICdk",
        "outputId": "6d38b56e-33cc-4ef0-b25d-c285ff51293c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/sypoo/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tqdm.pandas()\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JHAwgaWBCp4A"
      },
      "outputs": [],
      "source": [
        "train_dataframe = pd.read_csv(\"./train.csv\").iloc[:2000]\n",
        "valid_dataframe = pd.read_csv(\"./test.csv\").iloc[:400]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AGiKTX8FC6rY"
      },
      "outputs": [],
      "source": [
        "# train_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5xX7qoPbDJf9"
      },
      "outputs": [],
      "source": [
        "def preproc(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r\"([^\\w\\s]\\s)\", r\" \\1\", text)\n",
        "  text = re.sub(r\"(\\d)\\.\", r\"\\1 . \", text)\n",
        "  text = re.sub(r\"\\s+\", r\" \", text)\n",
        "  text = text.strip()\n",
        "  text = text.split(\" \")\n",
        "\n",
        "  morph = pymorphy3.MorphAnalyzer()\n",
        "  text = [morph.parse(word)[0].normal_form for word in text]\n",
        "\n",
        "  # stemmer = RussianStemmer()\n",
        "  # stemmed_words = [stemmer.stem(word) for word in text]\n",
        "\n",
        "  return text\n",
        "\n",
        "def slicingWindow(sequence):\n",
        "  pairs = []\n",
        "  for index, word in enumerate(sequence):\n",
        "    for jndex in [-2, -1, 1, 2]:\n",
        "      if 0 <= index+jndex < len(sequence):\n",
        "        pairs.append((sequence[index], sequence[index+jndex]))\n",
        "  return pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJhrUZ8prWmF",
        "outputId": "fef74c9a-604f-4423-878c-108b95d9c1de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['волшебный',\n",
              " 'фото',\n",
              " 'виктория',\n",
              " 'поплавский',\n",
              " 'евгений',\n",
              " '.',\n",
              " '2',\n",
              " '.',\n",
              " '3',\n",
              " '.',\n",
              " '1']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preproc(\"Волшебные фото Виктория Поплавская Евгения. 2.3.1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhlSr4r3EFwV",
        "outputId": "ba23cb93-29fb-4ebd-83e0-4f3cb3ab559c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('волшебный', 'фото'),\n",
              " ('волшебный', 'виктория'),\n",
              " ('фото', 'волшебный'),\n",
              " ('фото', 'виктория'),\n",
              " ('фото', 'поплавский'),\n",
              " ('виктория', 'волшебный'),\n",
              " ('виктория', 'фото'),\n",
              " ('виктория', 'поплавский'),\n",
              " ('виктория', 'евгений'),\n",
              " ('поплавский', 'фото'),\n",
              " ('поплавский', 'виктория'),\n",
              " ('поплавский', 'евгений'),\n",
              " ('поплавский', '.'),\n",
              " ('евгений', 'виктория'),\n",
              " ('евгений', 'поплавский'),\n",
              " ('евгений', '.'),\n",
              " ('евгений', '2'),\n",
              " ('.', 'поплавский'),\n",
              " ('.', 'евгений'),\n",
              " ('.', '2'),\n",
              " ('.', '.'),\n",
              " ('2', 'евгений'),\n",
              " ('2', '.'),\n",
              " ('2', '.'),\n",
              " ('2', '3'),\n",
              " ('.', '.'),\n",
              " ('.', '2'),\n",
              " ('.', '3'),\n",
              " ('.', '.'),\n",
              " ('3', '2'),\n",
              " ('3', '.'),\n",
              " ('3', '.'),\n",
              " ('3', '1'),\n",
              " ('.', '.'),\n",
              " ('.', '3'),\n",
              " ('.', '1'),\n",
              " ('.', '.'),\n",
              " ('1', '3'),\n",
              " ('1', '.'),\n",
              " ('1', '.'),\n",
              " ('.', '.'),\n",
              " ('.', '1')]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"   Волшебные фото Виктория Поплавская Евгения.   2.3.1.  \"\n",
        "sequence_of_words = preproc(text)\n",
        "slicingWindow(sequence_of_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UQgltXaELGa",
        "outputId": "c48bf284-caa5-4487-a325-0677ef696aa8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [01:44<00:00, 19.13it/s]\n",
            "100%|██████████| 2000/2000 [00:00<00:00, 8252.33it/s]\n",
            "100%|██████████| 400/400 [00:21<00:00, 18.86it/s]\n",
            "100%|██████████| 400/400 [00:00<00:00, 20180.20it/s]\n"
          ]
        }
      ],
      "source": [
        "train_pairs = train_dataframe[\"text\"].progress_apply(preproc).progress_apply(slicingWindow).explode().tolist()\n",
        "valid_pairs = valid_dataframe[\"text\"].progress_apply(preproc).progress_apply(slicingWindow).explode().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('волшебный', 'фото'),\n",
              " ('волшебный', 'виктория'),\n",
              " ('фото', 'волшебный'),\n",
              " ('фото', 'виктория'),\n",
              " ('фото', 'поплавский'),\n",
              " ('виктория', 'волшебный'),\n",
              " ('виктория', 'фото'),\n",
              " ('виктория', 'поплавский'),\n",
              " ('виктория', 'евгениямедведев'),\n",
              " ('поплавский', 'фото')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_pairs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JPKkEWv1wt-D"
      },
      "outputs": [],
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, pairs):\n",
        "    self.pairs = pairs\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.pairs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.pairs[index][0], self.pairs[index][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "b_HfxQoMp8SP"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "train_dataset = MyDataset(train_pairs)\n",
        "valid_dataset = MyDataset(valid_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bew30vL9peJm"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xKLtiiuiK4O8"
      },
      "outputs": [],
      "source": [
        "class Tokenizer:\n",
        "  def __init__(self, set_of_words):\n",
        "    self.__word2index = {}\n",
        "    self.__index2word = {}\n",
        "    for index, value in enumerate(set_of_words):\n",
        "      self.__word2index[value] = index\n",
        "      self.__index2word[index] = value\n",
        "\n",
        "  def __call__(self, sequence):\n",
        "    tokens = []\n",
        "    for word in sequence:\n",
        "      try:\n",
        "        tokens.append(self.__word2index[word.lower()])\n",
        "      except:\n",
        "        raise ValueError(\"Такого слова нет в токенизаторе\")\n",
        "    return torch.tensor(tokens)\n",
        "\n",
        "  def decode(self, sequence):\n",
        "    words = []\n",
        "    for index in sequence:\n",
        "      try:\n",
        "        words.append(self.__index2word[index])\n",
        "      except:\n",
        "        raise ValueError(\"Такого токена нет в токенизаторе\")\n",
        "    return words\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.__word2index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lkuOYL8k_lGR"
      },
      "outputs": [],
      "source": [
        "tokenizer_dataframe = pd.concat([train_dataframe[\"text\"], valid_dataframe[\"text\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdizgvEAH8Pk",
        "outputId": "706d907a-22ae-44d1-d20f-9a1d0a6d3712"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2400/2400 [02:08<00:00, 18.64it/s]\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer(set(tokenizer_dataframe.progress_apply(preproc).explode().tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt0OpvJiKThy",
        "outputId": "38995dc0-2873-4e06-b9a8-a113ebeb52e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([15968,  4878, 11257, 12421])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(preproc(\"Привет меня зовут Руслан\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqjIGUfYMYC6",
        "outputId": "92f86883-4540-4f2f-e4c2-938cff99174b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18728"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WTCn8nQKNDeU"
      },
      "outputs": [],
      "source": [
        "class word2vec(nn.Module):\n",
        "  def __init__(self, num_dict, hidden):\n",
        "    super().__init__()\n",
        "    self.encode = nn.Embedding(num_dict, hidden)\n",
        "    self.decode = nn.Linear(hidden, num_dict)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.encode(x)\n",
        "    out = self.decode(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fr3TeEeMoO_i"
      },
      "outputs": [],
      "source": [
        "num_dict = 18728\n",
        "hidden = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kBRa7H_ToAEq"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = word2vec(num_dict, hidden).to(device)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "epochs = range(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCn45buN6fIa",
        "outputId": "9d4c7473-15e6-4cea-afb4-49500a17635b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "sdIXc3mKoYqj"
      },
      "outputs": [],
      "source": [
        "train_loss_list = []\n",
        "valid_loss_list = []\n",
        "train_acc_list = []\n",
        "valid_acc_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6DryuWrzwi7",
        "outputId": "1f32c86b-c48f-469b-8d82-58add1a9dac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 4460/31061 [06:16<37:26, 11.84it/s, Loss=8.82, Accuracy=0]     \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m   loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     23\u001b[0m   train_loss_mean \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 25\u001b[0m   \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m   pbar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_acc}, refresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m (pbar \u001b[38;5;241m:=\u001b[39m tqdm(valid_dataloader)):\n",
            "File \u001b[0;32m~/mtuci/ml/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "File \u001b[0;32m~/mtuci/ml/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
            "File \u001b[0;32m~/mtuci/ml/.venv/lib/python3.12/site-packages/torch/optim/adam.py:244\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    232\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    234\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    235\u001b[0m         group,\n\u001b[1;32m    236\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m         state_steps,\n\u001b[1;32m    242\u001b[0m     )\n\u001b[0;32m--> 244\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "File \u001b[0;32m~/mtuci/ml/.venv/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/mtuci/ml/.venv/lib/python3.12/site-packages/torch/optim/adam.py:876\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    874\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 876\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/mtuci/ml/.venv/lib/python3.12/site-packages/torch/optim/adam.py:478\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    476\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m--> 478\u001b[0m     \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(params[i]):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in epochs:\n",
        "  print(f\"Epochs {epoch}\")\n",
        "\n",
        "  train_loss_mean = 0\n",
        "  valid_loss_mean = 0\n",
        "  train_acc_mean = 0\n",
        "  valid_acc_mean = 0\n",
        "\n",
        "  for data, target in (pbar := tqdm(train_dataloader)):\n",
        "    optim.zero_grad()\n",
        "\n",
        "    data = tokenizer(data).to(device)\n",
        "    target = tokenizer(target).to(device)\n",
        "\n",
        "    out = model(data)\n",
        "\n",
        "    train_acc = float((out.argmax(dim=1) == target).sum()/batch_size)\n",
        "    train_acc_mean += train_acc\n",
        "\n",
        "    target = F.one_hot(target, num_classes=num_dict).float()\n",
        "    loss = loss_fn(out, target)\n",
        "    loss.backward()\n",
        "    train_loss_mean += loss.item()\n",
        "\n",
        "    optim.step()\n",
        "\n",
        "    pbar.set_postfix({\"Loss\": loss.item(), \"Accuracy\": train_acc}, refresh=True)\n",
        "\n",
        "  for data, target in (pbar := tqdm(valid_dataloader)):\n",
        "    with torch.no_grad():\n",
        "      data = tokenizer(data).to(device)\n",
        "      target = tokenizer(target).to(device)\n",
        "\n",
        "      out = model(data)\n",
        "      valid_acc = float((out.argmax(dim=1) == target).sum()/batch_size)\n",
        "      valid_acc_mean += valid_acc\n",
        "\n",
        "      target = F.one_hot(target, num_classes=num_dict).float()\n",
        "      loss = loss_fn(out, target)\n",
        "      valid_loss_mean += loss.item()\n",
        "\n",
        "      pbar.set_postfix({\"Loss\": loss.item(), \"Accuracy\": valid_acc}, refresh=True)\n",
        "\n",
        "  train_loss_list.append(train_loss_mean/len(train_dataloader))\n",
        "  valid_loss_list.append(valid_loss_mean/len(valid_dataloader))\n",
        "  train_acc_list.append(train_acc_mean/len(train_dataloader))\n",
        "  valid_acc_list.append(valid_acc_mean/len(valid_dataloader))\n",
        "\n",
        "  print(f\"Train_loss: {train_loss_mean/len(train_dataloader)}\")\n",
        "  print(f\"Valid_loss: {valid_loss_mean/len(valid_dataloader)}\")\n",
        "  print(f\"Train_acc: {train_acc_mean/len(train_dataloader)}\")\n",
        "  print(f\"Valid_acc: {valid_acc_mean/len(valid_dataloader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn2FHAdw0W1B"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
